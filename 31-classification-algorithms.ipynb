{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find the best algorithm for the data\n",
    "#Data - > Sales data\n",
    "\n",
    "\n",
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.testing import all_estimators\n",
    "from sklearn import base\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.calibration import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.tree.tree import *\n",
    "from sklearn.gaussian_process.gpc import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.semi_supervised import * \n",
    "from sklearn.discriminant_analysis import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.feature_selection import RFE\n",
    "#from sklearn.naive_bayes import *\n",
    "\n",
    "import importlib\n",
    "\n",
    "\n",
    "estimators = all_estimators()\n",
    "\n",
    "class hello:\n",
    "    \n",
    "    def __init__(self, X, Y, param):\n",
    "        X.self = X\n",
    "        Y.self = Y\n",
    "        #param.self = param\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .20, random_state = 42)\n",
    "        count = 0\n",
    "        model = []\n",
    "        for name, class_ in estimators:    \n",
    "           if issubclass(class_, base.ClassifierMixin): \n",
    "\n",
    "            try:\n",
    "                model = eval(name)()\n",
    "                model_param = model.get_params()\n",
    "                \n",
    "                count = count+1\n",
    "                print('\\n\\n\\nAlgorithm No. ', count, name)\n",
    "                print(model_param)\n",
    "               \n",
    "                #Change user defined paramaters\n",
    "                #s={'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 3, 'n_estimators': 30, 'random_state': None}\n",
    "                #model.set_params(**param)\n",
    "                #print(model.get_params())\n",
    "                \n",
    "                #fit model with new changes paramerter\n",
    "                model_fit = model.fit(X_train, Y_train)\n",
    "                predicted = model_fit.predict(X_test)\n",
    "                residual = Y_test - predicted\n",
    "                #print('predicted',predicted)\n",
    "                \n",
    "                #evauation matrix\n",
    "                print(name, confusion_matrix(Y_test, predicted))\n",
    "                \n",
    "                # Feature Ranking\n",
    "                rank = RFE(model,5,step=1)\n",
    "                rank.fit(X_train,Y_train)\n",
    "                print('Ranking :',rank.ranking_)\n",
    "\n",
    "            except Exception as err:\n",
    "                print(\"An exception occurred\", err)\n",
    "                #exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Algorithm No.  1 AdaBoostClassifier\n",
      "{'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': None}\n",
      "AdaBoostClassifier [[78 21]\n",
      " [20 35]]\n",
      "Ranking : [3 1 1 4 1 1 1 2]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  2 BaggingClassifier\n",
      "{'base_estimator': None, 'bootstrap': True, 'bootstrap_features': False, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "BaggingClassifier [[79 20]\n",
      " [22 33]]\n",
      "An exception occurred The classifier does not expose \"coef_\" or \"feature_importances_\" attributes\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  3 BernoulliNB\n",
      "{'alpha': 1.0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True}\n",
      "BernoulliNB [[98  1]\n",
      " [52  3]]\n",
      "Ranking : [1 1 1 1 1 2 4 3]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  4 CalibratedClassifierCV\n",
      "{'base_estimator': None, 'cv': 'warn', 'method': 'sigmoid'}\n",
      "CalibratedClassifierCV [[96  3]\n",
      " [39 16]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred The classifier does not expose \"coef_\" or \"feature_importances_\" attributes\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  5 ComplementNB\n",
      "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'norm': False}\n",
      "ComplementNB [[73 26]\n",
      " [27 28]]\n",
      "Ranking : [1 4 2 1 3 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  6 DecisionTreeClassifier\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': None, 'splitter': 'best'}\n",
      "DecisionTreeClassifier [[77 22]\n",
      " [15 40]]\n",
      "Ranking : [4 1 1 3 2 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  7 ExtraTreeClassifier\n",
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'random'}\n",
      "ExtraTreeClassifier [[74 25]\n",
      " [24 31]]\n",
      "Ranking : [1 1 4 3 2 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  8 ExtraTreesClassifier\n",
      "{'bootstrap': False, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 'warn', 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "ExtraTreesClassifier [[85 14]\n",
      " [28 27]]\n",
      "Ranking : [2 1 1 3 4 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  9 GaussianNB\n",
      "{'priors': None, 'var_smoothing': 1e-09}\n",
      "GaussianNB [[79 20]\n",
      " [16 39]]\n",
      "An exception occurred The classifier does not expose \"coef_\" or \"feature_importances_\" attributes\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  10 GaussianProcessClassifier\n",
      "{'copy_X_train': True, 'kernel': None, 'max_iter_predict': 100, 'multi_class': 'one_vs_rest', 'n_jobs': None, 'n_restarts_optimizer': 0, 'optimizer': 'fmin_l_bfgs_b', 'random_state': None, 'warm_start': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessClassifier [[70 29]\n",
      " [22 33]]\n",
      "An exception occurred The classifier does not expose \"coef_\" or \"feature_importances_\" attributes\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  11 GradientBoostingClassifier\n",
      "{'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'presort': 'auto', 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "GradientBoostingClassifier [[78 21]\n",
      " [18 37]]\n",
      "Ranking : [3 1 2 4 1 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  12 KNeighborsClassifier\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
      "KNeighborsClassifier [[70 29]\n",
      " [23 32]]\n",
      "An exception occurred The classifier does not expose \"coef_\" or \"feature_importances_\" attributes\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  13 LabelPropagation\n",
      "{'alpha': None, 'gamma': 20, 'kernel': 'rbf', 'max_iter': 1000, 'n_jobs': None, 'n_neighbors': 7, 'tol': 0.001}\n",
      "LabelPropagation [[98  1]\n",
      " [53  2]]\n",
      "An exception occurred The classifier does not expose \"coef_\" or \"feature_importances_\" attributes\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  14 LabelSpreading\n",
      "{'alpha': 0.2, 'gamma': 20, 'kernel': 'rbf', 'max_iter': 30, 'n_jobs': None, 'n_neighbors': 7, 'tol': 0.001}\n",
      "LabelSpreading [[98  1]\n",
      " [53  2]]\n",
      "An exception occurred The classifier does not expose \"coef_\" or \"feature_importances_\" attributes\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  15 LinearDiscriminantAnalysis\n",
      "{'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}\n",
      "LinearDiscriminantAnalysis [[80 19]\n",
      " [18 37]]\n",
      "Ranking : [1 1 2 3 4 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  16 LinearSVC\n",
      "{'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n",
      "LinearSVC [[99  0]\n",
      " [54  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking : [1 2 1 4 3 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  17 LogisticRegression\n",
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'max_iter': 100, 'multi_class': 'warn', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'warn', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "LogisticRegression [[83 16]\n",
      " [21 34]]\n",
      "Ranking : [1 1 2 3 4 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  18 LogisticRegressionCV\n",
      "{'Cs': 10, 'class_weight': None, 'cv': 'warn', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1.0, 'max_iter': 100, 'multi_class': 'warn', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'refit': True, 'scoring': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionCV [[78 21]\n",
      " [19 36]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking : [1 1 2 3 4 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  19 MLPClassifier\n",
      "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "MLPClassifier [[84 15]\n",
      " [40 15]]\n",
      "An exception occurred The classifier does not expose \"coef_\" or \"feature_importances_\" attributes\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  20 MultinomialNB\n",
      "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}\n",
      "MultinomialNB [[74 25]\n",
      " [27 28]]\n",
      "Ranking : [1 4 2 1 3 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  21 NearestCentroid\n",
      "{'metric': 'euclidean', 'shrink_threshold': None}\n",
      "NearestCentroid [[79 20]\n",
      " [30 25]]\n",
      "An exception occurred The classifier does not expose \"coef_\" or \"feature_importances_\" attributes\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  22 NuSVC\n",
      "{'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'auto_deprecated', 'kernel': 'rbf', 'max_iter': -1, 'nu': 0.5, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "NuSVC [[99  0]\n",
      " [55  0]]\n",
      "An exception occurred The classifier does not expose \"coef_\" or \"feature_importances_\" attributes\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  23 PassiveAggressiveClassifier\n",
      "{'C': 1.0, 'average': False, 'class_weight': None, 'early_stopping': False, 'fit_intercept': True, 'loss': 'hinge', 'max_iter': None, 'n_iter': None, 'n_iter_no_change': 5, 'n_jobs': None, 'random_state': None, 'shuffle': True, 'tol': None, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "PassiveAggressiveClassifier [[99  0]\n",
      " [55  0]]\n",
      "Ranking : [1 1 1 4 1 2 3 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  24 Perceptron\n",
      "{'alpha': 0.0001, 'class_weight': None, 'early_stopping': False, 'eta0': 1.0, 'fit_intercept': True, 'max_iter': None, 'n_iter': None, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'random_state': 0, 'shuffle': True, 'tol': None, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "Perceptron [[81 18]\n",
      " [34 21]]\n",
      "Ranking : [1 1 1 4 1 3 2 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  25 QuadraticDiscriminantAnalysis\n",
      "{'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'store_covariances': None, 'tol': 0.0001}\n",
      "QuadraticDiscriminantAnalysis [[81 18]\n",
      " [16 39]]\n",
      "An exception occurred The classifier does not expose \"coef_\" or \"feature_importances_\" attributes\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  26 RadiusNeighborsClassifier\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'outlier_label': None, 'p': 2, 'radius': 1.0, 'weights': 'uniform'}\n",
      "An exception occurred No neighbors found for test samples [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153], you can try using larger radius, give a label for outliers, or consider removing them from your dataset.\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  27 RandomForestClassifier\n",
      "{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 'warn', 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "RandomForestClassifier [[81 18]\n",
      " [21 34]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking : [2 1 1 4 3 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  28 RidgeClassifier\n",
      "{'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': None, 'solver': 'auto', 'tol': 0.001}\n",
      "RidgeClassifier [[80 19]\n",
      " [18 37]]\n",
      "Ranking : [1 1 2 3 4 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  29 RidgeClassifierCV\n",
      "{'alphas': array([ 0.1,  1. , 10. ]), 'class_weight': None, 'cv': None, 'fit_intercept': True, 'normalize': False, 'scoring': None, 'store_cv_values': False}\n",
      "RidgeClassifierCV [[80 19]\n",
      " [19 36]]\n",
      "Ranking : [1 1 2 3 4 1 1 1]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  30 SGDClassifier\n",
      "{'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': None, 'n_iter': None, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'tol': None, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "SGDClassifier [[68 31]\n",
      " [25 30]]\n",
      "Ranking : [1 1 1 1 1 3 4 2]\n",
      "\n",
      "\n",
      "\n",
      "Algorithm No.  31 SVC\n",
      "{'C': 1.0, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'auto_deprecated', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "SVC [[99  0]\n",
      " [55  0]]\n",
      "An exception occurred The classifier does not expose \"coef_\" or \"feature_importances_\" attributes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import data using pandas\n",
    "df = pd.read_csv(\"data/pima-indians-diabetes.csv\")\n",
    "df.head()\n",
    "\n",
    "\n",
    "Y = df['class']\n",
    "X = df.drop(['class'], axis=1)\n",
    "\n",
    "#s = {'learning_rate': 3.0}\n",
    "s =''\n",
    "p1 = hello(X, Y, s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
