{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find the best algorithm for the data\n",
    "#Data - > Sales data\n",
    "\n",
    "\n",
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.testing import all_estimators\n",
    "from sklearn import base\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.calibration import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.tree.tree import *\n",
    "from sklearn.gaussian_process.gpc import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.semi_supervised import * \n",
    "from sklearn.discriminant_analysis import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.feature_selection import RFE\n",
    "#from sklearn.naive_bayes import *\n",
    "\n",
    "import importlib\n",
    "\n",
    "\n",
    "estimators = all_estimators()\n",
    "\n",
    "class hello:\n",
    "    \n",
    "    def __init__(self, X, Y, param):\n",
    "        X.self = X\n",
    "        Y.self = Y\n",
    "        \n",
    "        #Test Train Split\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .20, random_state = 42)\n",
    "        \n",
    "        model = []\n",
    "        arr = []\n",
    "        for name, class_ in estimators:    \n",
    "           if issubclass(class_, base.ClassifierMixin): \n",
    "\n",
    "            try:\n",
    "                model = eval(name)()\n",
    "                model_param = model.get_params()\n",
    "                \n",
    "               \n",
    "                #------Change user defined paramaters------\n",
    "                #s={'base_estimator': None, 'learning_rate': 3, 'n_estimators': 30, 'random_state': None}\n",
    "                model.set_params(**model_param)\n",
    "                #print(model.get_params())\n",
    "                \n",
    "                #fit model with new changes paramerter\n",
    "                model_fit = model.fit(X_train, Y_train)\n",
    "                predicted = model_fit.predict(X_test)\n",
    "                residual = Y_test - predicted\n",
    "                #print('predicted',predicted)\n",
    "                \n",
    "                #-------evauation matrix---------\n",
    "                cm = confusion_matrix(Y_test, predicted)\n",
    "                #print(name, cm)\n",
    "                recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "                precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "                np.mean(recall)\n",
    "                np.mean(precision)\n",
    "                \n",
    "                #-------Accuracy---------\n",
    "                diagonal_sum = cm.trace()\n",
    "                sum_of_all_elements = cm.sum()\n",
    "                accuracy = diagonal_sum / sum_of_all_elements\n",
    "                #--------------------------------------------------------------------\n",
    "                \n",
    "                arr.append([name, accuracy])\n",
    "                \n",
    "            except Exception as err:\n",
    "                print(\"An exception occurred\", err)\n",
    "        \n",
    "        #convert list to data frame        \n",
    "        df = pd.DataFrame(arr, columns=['Algorithm','Accuracy'])\n",
    "        print (df)\n",
    "        print ('\\nHighest Accuracy')\n",
    "        print (df[(df['Accuracy'] == max(df['Accuracy']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred No neighbors found for test samples [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153], you can try using larger radius, give a label for outliers, or consider removing them from your dataset.\n",
      "                        Algorithm  Accuracy\n",
      "0              AdaBoostClassifier  0.733766\n",
      "1               BaggingClassifier  0.733766\n",
      "2                     BernoulliNB  0.655844\n",
      "3          CalibratedClassifierCV  0.727273\n",
      "4                    ComplementNB  0.655844\n",
      "5          DecisionTreeClassifier  0.759740\n",
      "6             ExtraTreeClassifier  0.642857\n",
      "7            ExtraTreesClassifier  0.727273\n",
      "8                      GaussianNB  0.766234\n",
      "9       GaussianProcessClassifier  0.668831\n",
      "10     GradientBoostingClassifier  0.746753\n",
      "11           KNeighborsClassifier  0.662338\n",
      "12               LabelPropagation  0.649351\n",
      "13                 LabelSpreading  0.649351\n",
      "14     LinearDiscriminantAnalysis  0.759740\n",
      "15                      LinearSVC  0.370130\n",
      "16             LogisticRegression  0.759740\n",
      "17           LogisticRegressionCV  0.740260\n",
      "18                  MLPClassifier  0.629870\n",
      "19                  MultinomialNB  0.662338\n",
      "20                NearestCentroid  0.675325\n",
      "21                          NuSVC  0.642857\n",
      "22    PassiveAggressiveClassifier  0.662338\n",
      "23                     Perceptron  0.662338\n",
      "24  QuadraticDiscriminantAnalysis  0.779221\n",
      "25         RandomForestClassifier  0.733766\n",
      "26                RidgeClassifier  0.759740\n",
      "27              RidgeClassifierCV  0.753247\n",
      "28                  SGDClassifier  0.655844\n",
      "29                            SVC  0.642857\n",
      "\n",
      "Highest Accuracy\n",
      "                        Algorithm  Accuracy\n",
      "24  QuadraticDiscriminantAnalysis  0.779221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:69: RuntimeWarning: invalid value encountered in true_divide\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\dinesh grewal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:69: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "#Import data using pandas\n",
    "df = pd.read_csv(\"data/pima-indians-diabetes.csv\")\n",
    "df.head()\n",
    "\n",
    "\n",
    "Y = df['class']\n",
    "X = df.drop(['class'], axis=1)\n",
    "\n",
    "#s = {'learning_rate': 3.0}\n",
    "s =''\n",
    "#call class Hllo\n",
    "f = hello(X, Y, s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
